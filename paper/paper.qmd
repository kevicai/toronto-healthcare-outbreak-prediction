---
title: "Analyzing the Factors Influencing Outbreak Duration in Toronto Healthcare Institutions"
subtitle: "My subtitle if needed"
author: 
  - Kevin Cai
thanks: "Code and data are available at: [https://github.com/kevicai/toronto-healthcare-outbreak-prediction](https://github.com/kevicai/toronto-healthcare-outbreak-prediction)."
date: today
date-format: long
abstract: "First sentence. Second sentence. Third sentence. Fourth sentence."
format: pdf
number-sections: true
bibliography: references.bib
---

```{r}
#| include: false
#| warning: false
#| message: false

library(tidyverse)
library(knitr)
library(ggplot2)
library("rstanarm")
library("caret")
library("loo")
```


# Introduction {#sec-intro}

Overview paragraph

Estimand paragraph

Results paragraph

Why it matters paragraph

Telegraphing paragraph: The remainder of this paper is structured as follows. @sec-data....


# Data {#sec-data}

## Overview

This report uses the Outbreaks in Toronto Healthcare Institutions dataset, contains data from January 2016 to November 2024. The dataset is provided by Toronto Public Health, through City of Toronto Open Data Portal [@datasource]. The dataset tracks reported outbreaks of gastroenteric and respiratory illnesses in Toronto healthcare institutions and contains detailed information on outbreak settings, causative agents, and outbreak durations. Following the principles from Telling Stories with Data [@textbook], we examine how the characteristics of outbreaks, such as the type of healthcare institution, the causative agent, and the month the outbreak began, influence their durations. A sample of the cleaned dataset is shown in @tbl-cleaned. 

```{r, message = FALSE, echo = FALSE}
#| label: tbl-cleaned
#| tbl-cap: "Sample of Cleaned Outbreaks in Toronto Healthcare Institution Data"
data <- read.csv(here::here("data/02-analysis_data/analysis_data.csv"))
head(data, 5) |>
    kable(col.names = c("Outbreak Setting", "Causative Agent", "Month", "Outbreak Duration"))
```

There is 5387 observations in the orginal dataset and 1119 observations were removed that contained missing, invalid, or irrelivant data of the variables we're interested in. The data was first downloaded using `Python` [@citePython] and cleaned with the `pandas` package [@citePandas]. The cleaning process involved converting dates to a standardized datetime format, creating a "duration" variable representing the length of each outbreak, and extracting the month of the outbreak's start. Irrelevant columns were removed, and variables were renamed for clarity. Causative agents were grouped into broader categories, and rows with missing or invalid data were removed, including those with unidentifiable causative agents or certain outbreak settings. The final dataset was saved for further analysis.

`R` [@citeR] is used for the generation of figures, graphs, and tables throughout this paper. Specifically, the `rstanarm` package [@rstanarm] was employed to fit the model. For data manipulation, the `dplyr` package [@dplyr] was utilized to clean and transform the data efficiently. The `caret` package [@caret] was used for model training, while `modelsummary` [@modelsummary] was used to produce concise tables summarizing the model output. The `loo` package [@loo] was used to perform leave-one-out cross-validation, which helped assess the model’s predictive performance. Finally, the package `ggplot2` is used to generate graphics and figures for this analysis.

## Measurement
	
The data was primarily collected through mandatory reporting by healthcare institutions to Toronto Public Health under the Ontario Health Protection and Promotion Act (HPPA). Reports of suspected or confirmed outbreaks include both gastroenteric and respiratory illnesses. These reports are based on active monitoring by institutional staff, who observe and document signs and symptoms such as nausea, vomiting, fever, cough, or sore throat.

Some details, such as the causative agent group, may initially be unconfirmed and later identified through laboratory tests or clinical evaluations. However, these identifications are not always definitive. For instance, "Coronavirus*" in the dataset refers to seasonal coronaviruses, which are commonly implicated in respiratory outbreaks, and does not include COVID-19.

The unit of measurement for outbreak duration is in days. Other data fields, such as outbreak setting and causative agent group, are categorical features without numerical units. The dataset is updated weekly, ensuring it reflects the most recent outbreak data available.

## Outcome variable

### Duration
The Duration variable is numerical and indicates the total number of days each outbreak lasted. This reflects the severity and magnitude of the outbreak. It is constructed from the dataset by calculating the difference between the outbreak start and end dates.

```{r, message = FALSE, echo = FALSE}
#| label: fig-duration
#| fig-cap: "Distribution of Outbreak Duration"
ggplot(data, aes(x = duration)) +
  geom_histogram(fill = "steelblue", binwidth = 5, alpha = 0.8) +
  labs(
    x = "Duration (Days)",
    y = "Frequency"
  ) +
  theme_minimal() +
  theme(
    axis.text = element_text(size = 8),
    axis.title = element_text(size = 10)
  )
```

```{r, message = FALSE, echo = FALSE}
#| label: tbl-duration-mean-var
#| tbl-cap: "Summary of Outbreak Duration: Mean and Variance"
mean_duration <- mean(data$duration)
var_duration <- var(data$duration)

tibble(
  Statistic = c("Mean Duration", "Variance"),
  Value = c(mean_duration, var_duration)
) |> 
  kable(col.names = c("Statistic", "Value"))
```

Longer outbreak durations may indicate challenges in containment, possibly influenced by the Outbreak Setting and Causative Agent.

## Predictor variables

### Outbreak Setting
The Outbreak Setting variable is categorical and identifies the type of healthcare institution where the outbreak occurred, such as hospitals, long-term care homes (LTCH), or retirement homes. It provides insights into the environments most affected by outbreaks.

@fig-setting-count illustrates the count of outbreaks across different settings in the dataset. 

```{r, message = FALSE, echo = FALSE}
#| label: fig-setting-count
#| fig-cap: "Outbreak occurrence in healthcare settings"
outbreak_setting_count <- data |>
  count(outbreak_setting, name = "count") |>
  mutate(percentage = (count / sum(count)) * 100) |>
  arrange(desc(count))

# Bar graph for Outbreak Setting
ggplot(outbreak_setting_count, aes(x = reorder(outbreak_setting, -count), y = count)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  geom_text(aes(label = sprintf("%.1f%%", percentage)), hjust = -0.1, size = 3) +
  scale_y_continuous(expand = expansion(mult = c(0.02, 0.2))) + # Add right padding
  coord_flip() + 
  labs(
    x = "Outbreak Setting",
    y = "Count"
  ) +
  theme_minimal() +
  theme(
    axis.text = element_text(size = 8),
    axis.title = element_text(size = 10)
  )
```

LTCH (Long-Term Care Homes) accounts for a significant portion of outbreaks, likely due to the vulnerability of their populations. Comparing the frequency of outbreaks across settings can reveal risk patterns.

### Causative Agent
The Causative Agent variable is categorical and reflects the infectious agents responsible for outbreaks. While the original dataset contains 55 agents, they are grouped into seven broader categories to simplify the analysis and enhance interpretability.

@fig-agent-count illustrates the count and percentage distribution of causative agents in the dataset.

```{r, message = FALSE, echo = FALSE}
#| label: fig-agent-count
#| fig-cap: "Outbreak causative agent count and percentage"
outbreak_agent_count <- data |>
  count(causative_agent, name = "count") |>
  mutate(percentage = (count / sum(count)) * 100) |>
  arrange(desc(count))

# Bar graph for Causative Agents
ggplot(outbreak_agent_count, aes(x = reorder(causative_agent, -count), y = count)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  geom_text(aes(label = sprintf("%.1f%%", percentage)), hjust = -0.1, size = 3) +
  scale_y_continuous(expand = expansion(mult = c(0.02, 0.2))) + # Add right padding
  coord_flip() +
  labs(
    x = "Causative Agent",
    y = "Count"
  ) +
  theme_minimal() +
  theme(
    axis.text = element_text(size = 8),
    axis.title = element_text(size = 10),
    plot.margin = margin(1, 1.2, 1, 1, "cm")
  )
```

### Month Outbreak Began
The Month variable is numerical and records the calendar month when each outbreak started. It reflects seasonal trends and potential patterns in infection rates. This variable is extracted from the date where each outbreak began from the original dataset. 

@fig-month shows the the occurance of outbreaks in each month, with winter months having siginifiantly more outbreaks compared to other months. This suggest that seasons have effects on outbreak occurances.

@fig-month-duration the boxplot visualizes the distribution of outbreak durations for each month. The duration of months January to November outbreaks appears similar, while December has a noticeable increase in duration compared to other months.

```{r, message = FALSE, echo = FALSE}
#| label: fig-month
#| fig-cap: "Seasonal trends in outbreak occurrence and percentage"
outbreak_month_count <- data |>
  count(month, name = "count") |>
  arrange(desc(month))

ggplot(outbreak_month_count, aes(x = month, y = count)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  labs(
    x = "Month",
    y = "Count"
  ) +
  theme_minimal() +
  theme(
    axis.text = element_text(size = 8),
    axis.title = element_text(size = 10)
  )
```

```{r, message = FALSE, echo = FALSE}
#| label: fig-month-duration
#| fig-cap: "Duration of outbreaks across different months"
# Scatter plot for month vs. duration
ggplot(data, aes(x = as.factor(month), y = duration)) +
  geom_boxplot(fill = "steelblue", alpha = 0.7) +
  labs(
    x = "Month",
    y = "Duration (days)",
    title = "Duration of Outbreaks Across Months"
  ) +
  theme_minimal() +
  theme(
    axis.text = element_text(size = 8),
    axis.title = element_text(size = 10),
    plot.title = element_text(size = 12, face = "bold")
  )
```

# Model

## Model Overview

To better understand the factors influencing the duration of outbreaks in Toronto healthcare facilities, a statistical model was developed using the negative binomial regression framework. This model was chosen because the outcome variable of interest, outbreak duration, is a count variable with evidence of overdispersion—where the variance exceeds the mean [@textbook]. Additionally, this model was Bayesian, meaning the parameters were treated as random variables with prior probability distributions reflecting initial beliefs about their values before considering the data.

## Model Setup

The setup for the Bayesian negative binomial regression model used in this analysis is as follows:

\begin{align} 
y_i | \lambda_i &\sim \text{Negative Binomial}(\lambda_i, \phi) \\
\log(\lambda_i) &= \beta_0 + \beta_1 \times \text{outbreak\_setting}_i + \beta_2 \times \text{causative\_agent}_i + \beta_3 \times \text{month}_i \\
\beta_0 &\sim \text{Normal}(0, 2.5) \\
\beta_1 &\sim \text{Normal}(0, 2.5) \\
\beta_2 &\sim \text{Normal}(0, 2.5) \\
\beta_3 &\sim \text{Normal}(0, 2.5) \\
\phi &\sim \text{Exponential}(1)
\end{align}

In the above model:

- $\lambda_i$ is the expected duration of outbreak $i$, modeled through a log link.
- $\beta_0$ is the intercept term.
- $\beta_1$ is the coefficient for the **outbreak setting**.
- $\beta_2$ is the coefficient for the **causative agent**.
- $\beta_3$ is the coefficient for the **month** when the outbreak started.
- $\phi$ is the **dispersion parameter** that controls the degree of overdispersion in the negative binomial distribution.

- All coefficients ($\beta_0, \beta_1, \beta_2, \beta_3$) are assigned **Normal(0, 2.5)** priors.
- The dispersion parameter $\phi$ is assigned an **Exponential(1)** prior, reflecting our belief that the variance is greater than the mean.

## Model Selection

```{r, message = FALSE, echo = FALSE}
#| label: load-models
library(rstanarm)
poisson_model <-
    readRDS(file = here::here("models/poisson_model.rds"))
neg_binomial_model <- 
    readRDS(file = here::here("models/neg_binomial_model.rds"))
```

Both negative binomial model and Poisson model for the dataset was constructed using the `rstanarm` package [@rstanarm] and R [@citeR]. But the negative binomial model was chosen over the Poisson model for several reasons. First, as shown in @tbl-modelresults, the variance of the outcome variable, duration, is significantly higher than the mean, indicating overdispersion. The Poisson model assumes equal mean and variance, which is not suitable in this case. The negative binomial model relaxes this assumption, allowing for overdispersion and providing a better fit for the data [@textbook].Additionally, the Leave-One-Out Cross Validation (LOO-CV) results in @tbl-loo-comparison show that the negative binomial model has a higher ELPD (Expected Log Pointwise Predictive Density) compared to the Poisson model. The ELPD is a metric that measures the model’s predictive performance, with higher values indicating a better fit to the data  [@textbook]. The fact that the negative binomial model outperforms the Poisson model in this regard suggests that it is more effective at capturing the underlying patterns of the outbreak duration data.

Other regression models like logistic regression were not chosen because logistic regression is designed for modeling binary outcomes. Since our outcome variable, duration, is a continuous count variable representing the number of days an outbreak lasts, logistic regression is not appropriate because it cannot model continuous or count data. Linear regression was also not chosen because Poission and negative binomial distributions are more suitable for modeling count data like outbreak duration in days, where as linear regression is more suitible for continuous data.

## Model Diagnostics and Validation

We conducted several key validation checks to assess its predictive performance and overall adequacy. Aside from using LOO Cross Validation technique, we also calculated the Mean Absolute Error (MAE) for both models as a metric to assess the predictive performance of the Negative Binomial model over the Poisson model. To ensure the model doesn't over fit the training data, we first split the data into training and test sets. The data was randomly divided using the `caret` package [@caret], with 80% used for model training and the remaining 20% reserved for testing. We used both models to predict the outcome variable (outbreak duration) on the test set and compared the predicted values to the actual values from the test set to compute the MAE for each model.

```{r, message = FALSE, echo = FALSE}
#| label: tbl-mae-comparison
#| tbl-cap: "Comparison of Mean Absolute Error (MAE) for Poisson and Negative Binomial Models"
test_data <- read.csv(here::here("data/02-analysis_data/test_data.csv"))

# Convert variables to factors
test_data <- test_data |>
  mutate(
    outbreak_setting = factor(outbreak_setting),
    causative_agent = factor(causative_agent),
    month = factor(month)
  )

poisson_pred <- predict(poisson_model, newdata = test_data, type = "response")
neg_binomial_pred <- predict(neg_binomial_model, newdata = test_data, type = "response")
 
# Compute MAEs and present in a table
mae_poisson <- round(mean(abs(test_data$duration - poisson_pred)), 2)
mae_neg_binomial <- round(mean(abs(test_data$duration - neg_binomial_pred)), 2)

mae_table <- tibble(
  Model = c("Poisson Model", "Negative Binomial Model"),
  MAE = c(mae_poisson, mae_neg_binomial)
)

mae_table |>
  kable(col.names = c("Model", "Mean Absolute Error (MAE)")) 
```

From @tbl-mae-comparison, the MAE for the Poisson model is 6.53, while the MAE for the Negative Binomial model is 6.52. The difference between the MAEs is minimal, suggesting that both models perform similarly in terms of prediction accuracy. However, the Negative Binomial model may still be preferred as it accounts for overdispersion, which is more appropriate for count data. The MAE of 6.52 means that, on average, the predicted outbreak duration from the Negative Binomial model deviates from the actual duration by approximately 6.52 days. In other words, for any given outbreak in the test data, the model's prediction of the outbreak's duration is off by around 6.5 days, either overestimating or underestimating the actual duration.

# Results

Our results are summarized in @tbl-model-results.

```{r, message = FALSE, echo = FALSE}
#| label: tbl-model-results
#| tbl-cap: "Explanatory models of flight time based on wing width and wing length"

# modelsummary::modelsummary(
#     list(
#         "Model" = model
#     ),
#     statistic = "mad",
#     fmt = 2
# )
```




# Discussion

## First discussion point {#sec-first-point}

If my paper were 10 pages, then should be be at least 2.5 pages. The discussion is a chance to show off what you know and what you learnt from all this. 

## Second discussion point

Please don't use these as sub-heading labels - change them to be what your point actually is.

## Third discussion point

## Weaknesses and next steps

Weaknesses and next steps should also be included.

\newpage

\appendix

# Appendix {-}


# Additional data details

# Model details {#sec-model-details}

## Outcome Variable Variance and Mean 

## Posterior predictive check

In @fig-ppchecks, using code adapted from @textbook, posterior prediction checks were performed for both the Poisson model and the negative binomial model. The figure show how well the model is able to predict the observed outcomes.

```{r, message = FALSE, echo = FALSE}
#| label: fig-ppchecks
#| layout-ncol: 2
#| fig-cap: "Comparing posterior prediction checks for the Poisson model and the negative binomial model"
#| fig-subcap: ["Poisson model posterior prediction check", "Negative binomial model posterior prediction check"]
pp_check(poisson_model) +
  theme_classic() +
  theme(legend.position = "bottom")

pp_check(neg_binomial_model) +
  theme_classic() +
  theme(legend.position = "bottom")
```

## Leave-One-Out (LOO) Cross Validation (CV) Comparison

In @fig-loo-comparison, we compare LOO performance of the Poission model against the negative binomial model based on the expected log pointwise predictive density (ELPD) and find that the negative binomial model has a higher ELPD value.

```{r, message = FALSE, echo = FALSE}
#| label: tbl-loo-comparison
#| tbl-cap: "Comparing LOO for Poisson and negative binomial models"
poisson_loo <- loo(poisson_model, cores = 2)
neg_binomial_loo <- loo(neg_binomial_model, cores = 2)

loo_comparison <- loo_compare(poisson_loo, neg_binomial_loo)
loo_comparison
```

## Diagnostics

<!-- ```{r}
#| echo: false
#| eval: true
#| message: false
#| warning: false
#| label: fig-stanareyouokay
#| fig-cap: "Checking the convergence of the MCMC algorithm"
#| fig-subcap: ["Trace plot", "Rhat plot"]
#| layout-ncol: 2

plot(model, "trace")

plot(model, "rhat")
``` -->



\newpage


# References


